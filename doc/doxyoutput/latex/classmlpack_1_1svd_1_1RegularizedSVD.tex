\doxysection{Regularized\+SVD$<$ Optimizer\+Type $>$ Class Template Reference}
\label{classmlpack_1_1svd_1_1RegularizedSVD}\index{RegularizedSVD$<$ OptimizerType $>$@{RegularizedSVD$<$ OptimizerType $>$}}


Regularized SVD is a matrix factorization technique that seeks to reduce the error on the training set, that is on the examples for which the ratings have been provided by the users.  


\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\textbf{ Regularized\+SVD} (const size\+\_\+t iterations=10, const double alpha=0.\+01, const double lambda=0.\+02)
\begin{DoxyCompactList}\small\item\em Constructor for Regularized SVD. \end{DoxyCompactList}\item 
void \textbf{ Apply} (const arma\+::mat \&data, const size\+\_\+t rank, arma\+::mat \&u, arma\+::mat \&v)
\begin{DoxyCompactList}\small\item\em Obtains the user and item matrices using the provided data and rank. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\subsubsection*{template$<$typename Optimizer\+Type = ens\+::\+Standard\+SGD$>$\newline
class mlpack\+::svd\+::\+Regularized\+SVD$<$ Optimizer\+Type $>$}

Regularized SVD is a matrix factorization technique that seeks to reduce the error on the training set, that is on the examples for which the ratings have been provided by the users. 

It is a fairly straightforward technique where the user and item matrices are updated with the help of Stochastic Gradient Descent(\+SGD) updates. The updates also penalize the learning of large feature values by means of regularization. More details can be found in the following links\+:

{\texttt{ http\+://sifter.\+org/$\sim$simon/journal/20061211.\+html}} {\texttt{ http\+://www.\+cs.\+uic.\+edu/$\sim$liub/\+KDD-\/cup-\/2007/proceedings/\+Regular-\/\+Paterek.\+pdf}}

An example of how to use the interface is shown below\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{arma::mat data; \textcolor{comment}{// Rating data in the form of coordinate list.}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keyword}{const} \textcolor{keywordtype}{size\_t} rank = 20; \textcolor{comment}{// Rank used for the decomposition.}}
\DoxyCodeLine{\textcolor{keyword}{const} \textcolor{keywordtype}{size\_t} iterations = 10; \textcolor{comment}{// Number of iterations used for optimization.}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keyword}{const} \textcolor{keywordtype}{double} alpha = 0.01 \textcolor{comment}{// Learning rate for the SGD optimizer.}}
\DoxyCodeLine{\textcolor{keyword}{const} \textcolor{keywordtype}{double} lambda = 0.1 \textcolor{comment}{// Regularization parameter for the optimization.}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Make a RegularizedSVD object.}}
\DoxyCodeLine{RegularizedSVD<> rSVD(iterations, alpha, lambda);}
\DoxyCodeLine{}
\DoxyCodeLine{arma::mat u, v; \textcolor{comment}{// User and item matrices.}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Use the Apply() method to get a factorization.}}
\DoxyCodeLine{rSVD.Apply(data, rank, u, v);}

\end{DoxyCode}
 

Definition at line 58 of file regularized\+\_\+svd.\+hpp.



\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\label{classmlpack_1_1svd_1_1RegularizedSVD_a9fa7f730b10a1dcceeb9257ddbfd71c8}} 
\index{RegularizedSVD$<$ OptimizerType $>$@{RegularizedSVD$<$ OptimizerType $>$}!RegularizedSVD@{RegularizedSVD}}
\index{RegularizedSVD@{RegularizedSVD}!RegularizedSVD$<$ OptimizerType $>$@{RegularizedSVD$<$ OptimizerType $>$}}
\doxysubsubsection{RegularizedSVD()}
{\footnotesize\ttfamily \textbf{ Regularized\+SVD} (\begin{DoxyParamCaption}\item[{const size\+\_\+t}]{iterations = {\ttfamily 10},  }\item[{const double}]{alpha = {\ttfamily 0.01},  }\item[{const double}]{lambda = {\ttfamily 0.02} }\end{DoxyParamCaption})}



Constructor for Regularized SVD. 

Obtains the user and item matrices after training on the passed data. The constructor initiates an object of class \doxyref{Regularized\+SVDFunction}{p.}{classmlpack_1_1svd_1_1RegularizedSVDFunction} for optimization. It uses the SGD optimizer by default. The optimizer uses a template specialization of Optimize().


\begin{DoxyParams}{Parameters}
{\em iterations} & Number of optimization iterations. \\
\hline
{\em alpha} & Learning rate for the SGD optimizer. \\
\hline
{\em lambda} & Regularization parameter for the optimization. \\
\hline
\end{DoxyParams}


\doxysubsection{Member Function Documentation}
\mbox{\label{classmlpack_1_1svd_1_1RegularizedSVD_a2a573625e4555fd5afc38af3529e07ec}} 
\index{RegularizedSVD$<$ OptimizerType $>$@{RegularizedSVD$<$ OptimizerType $>$}!Apply@{Apply}}
\index{Apply@{Apply}!RegularizedSVD$<$ OptimizerType $>$@{RegularizedSVD$<$ OptimizerType $>$}}
\doxysubsubsection{Apply()}
{\footnotesize\ttfamily void Apply (\begin{DoxyParamCaption}\item[{const arma\+::mat \&}]{data,  }\item[{const size\+\_\+t}]{rank,  }\item[{arma\+::mat \&}]{u,  }\item[{arma\+::mat \&}]{v }\end{DoxyParamCaption})}



Obtains the user and item matrices using the provided data and rank. 


\begin{DoxyParams}{Parameters}
{\em data} & Rating data matrix. \\
\hline
{\em rank} & Rank parameter to be used for optimization. \\
\hline
{\em u} & Item matrix obtained on decomposition. \\
\hline
{\em v} & User matrix obtained on decomposition. \\
\hline
\end{DoxyParams}


Referenced by Reg\+SVDPolicy\+::\+Apply().



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/home/aakash/mlpack/src/mlpack/methods/regularized\+\_\+svd/\textbf{ regularized\+\_\+svd.\+hpp}\end{DoxyCompactItemize}
